<!-- livebook:{"app_settings":{"access_type":"public","slug":"app"}} -->

# LM Prompting

```elixir
Mix.install([
  {:kino, "~> 0.9.1"},
  {:poison, "~> 4.0"},
  {:httpoison, "~> 1.8"},
  {:explorer, "~> 0.5.0"},
  {:kino_explorer, "~> 0.1.7"}
])
```

## Section

```elixir
defmodule OpenAIClient do
  require HTTPoison

  defstruct [:openai_key, :model]

  def new(openai_key \\ nil, openai_key_path \\ nil) do
    key =
      case openai_key do
        nil -> load_openai_key(openai_key_path)
        _ -> openai_key
      end

    %OpenAIClient{:openai_key => key}
  end

  def load_openai_key(path \\ "openai_medsi_key.txt") do
    {:ok, key} = File.read(Path.expand(path))
    String.trim(key)
  end

  def get_completion_body(client, prompt, model) do
    headers = [
      {"Content-Type", "application/json"},
      {"Authorization", "Bearer #{client.openai_key}"}
    ]

    body =
      Poison.encode!(%{
        "model" => model,
        "prompt" => prompt,
        "temperature" => 0.9,
        "max_tokens" => 150,
        "top_p" => 1,
        "frequency_penalty" => 0.0,
        "presence_penalty" => 0.6,
        "stop" => [" Human:", " AI:"]
      })

    options = [:recv_timeout, 15000]
    {:ok, response} = _post_to_openai(body, headers, options)
    Poison.decode!(response.body)
  end

  def _post_to_openai(body, headers, options) do
    case HTTPoison.post("https://api.openai.com/v1/completions", body, headers, options) do
      {:ok, response} -> {:ok, response}
      {:error, _} -> _post_to_openai(body, headers, options)
    end
  end

  def get_completion(client, prompt, model \\ "text-davinci-003") do
    body = get_completion_body(client, prompt, model)
    [record | _] = body["choices"]
    record["text"]
  end
end
```

```elixir
defmodule Generator do
  def openai_client do
    OpenAIClient.new(nil, "openai_key.txt")
  end

  def generate(prompt, model \\ "text-davinci-003") do
    openai_client() |> OpenAIClient.get_completion(prompt, model)
  end
end
```

```elixir
response = Generator.generate("a cat walks into a bar")
```

```elixir
Kino.Markdown.new("### Chat\n----------")
```

```elixir
models = ["text-davinci-003", "gpt-3.5-turbo-0613", "gpt-4-0613"]

inputs = [
  prompt: Kino.Input.text("Prompt"),
  model: Kino.Input.select("model", for(m <- models, do: {m, m}))
]

chat_form = Kino.Control.form(inputs, submit: "Send", reset_on_submit: [:prompt])
```

```elixir
frame = Kino.Frame.new()
```

```elixir
Kino.Markdown.new("### Viewable table results\n------------")
```

```elixir
json_frame = Kino.Frame.new()
```

```elixir
Kino.Markdown.new("### Exportable results in JSONLines\n----------")
```

```elixir
table_frame = Kino.Frame.new()
```

```elixir
defmodule KinoUtils do
  def prettyprint(record) do
    ~s"""
    #### prompt:
    #{record["prompt"]},
    #### response:
    #{record["response"]}
    """
    |> String.trim()
  end

  def prepare_outputs(prompt, response) do
    %{"prompt" => prompt, "response" => response}
  end

  def display_tables(prompt, response, table_frame, json_frame) do
    record = prepare_outputs(prompt, response)
    Kino.Frame.append(table_frame, Kino.Text.new(Poison.encode!(record)))
    Kino.Frame.append(json_frame, Kino.Markdown.new(prettyprint(record)))
  end
end

Kino.listen(chat_form, fn %{data: %{prompt: prompt, model: model}, origin: origin} ->
  if prompt != "" do
    prompt_md = Kino.Markdown.new("**user**: #{prompt}. Generating...")
    Kino.Frame.append(frame, prompt_md)
    response = Generator.generate(prompt, model)
    content_md = Kino.Markdown.new("**bot**: #{response}")
    Kino.Frame.append(frame, content_md)
    KinoUtils.display_tables(prompt, response, table_frame, json_frame)
  else
    content = Kino.Markdown.new("_ERROR! You need a name and message to submit..._")
    Kino.Frame.append(frame, content, to: origin)
  end
end)
```
